{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cifar10.get_path().is_file():\n",
    "    cifar10.download()\n",
    "else:\n",
    "    print(\"cifar10 is already downloaded at:\\n{}\".format(cifar10.get_path()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = (i.astype(\"float32\") for i in cifar10.load())\n",
    "x_train = x_train.transpose([0,2,3,1])\n",
    "x_test = x_test.transpose([0,2,3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('\\n')\n",
    "print('data type: {}'.format(x_train.dtype))\n",
    "print('label type: {}'.format(y_train.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represented by a 32x32x3 array\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the class-label for image-0\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_train[0].astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize examples\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "fig, axes = plt.subplots(nrows=samples_per_class, ncols=num_classes)\n",
    "\n",
    "for label_ind, cls in enumerate(classes):\n",
    "    idxs = np.where(y_train == label_ind)[0]\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        axes[i, label_ind].imshow(x_train[idx].astype('uint8'))\n",
    "        axes[i, label_ind].xaxis.set_major_locator(plt.NullLocator())\n",
    "        axes[i, label_ind].yaxis.set_major_locator(plt.NullLocator())\n",
    "        if i == 0:\n",
    "            axes[i, label_ind].set_title(cls)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train[:5000], y_train[:5000]\n",
    "x_test, y_test = x_test[:500], y_test[:500]\n",
    "print('Training data shape: ', x_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape-(5000, 32, 32, 3) -> shape-(5000, 3072)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], -1))\n",
    "\n",
    "# shape-(500, 32, 32, 3) -> shape-(500, 3072)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], -1))\n",
    "print(\"new train-shape:\", x_train.shape)\n",
    "print(\"new test-shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances(x, y):\n",
    "    \"\"\" computes the L2 distance between each row in `x` and `y`\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray\n",
    "            x.shape must be (M, D)\n",
    "            Each row of `x` is a flattened vector representing the pixel \n",
    "            values of a single image. Thus `x` represents\n",
    "            M images, each one described by a length-D vector.\n",
    "\n",
    "        y : numpy.ndarray\n",
    "            y.shape must be (N, D)\n",
    "            Each row of `y` is a flattened vector representing the pixel \n",
    "            values of a single image. Thus `y` represents\n",
    "            N images, each one described by a length-D vector.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        distances : numpy.ndarray\n",
    "            distances.shape = (M, N)\n",
    "            distances[i, j] = the L2 distance between x[i] and y[j]\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "    distance = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            distance[i, j] = np.sqrt(np.sum(np.square(x[i] - y[j])))\n",
    "    return distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.nearest_neighbors import grade_distances\n",
    "grade_distances(compute_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dists = compute_distances(x_test, x_train)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(dists, interpolation='none', cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dists, labels, k=1):\n",
    "    \"\"\" With a shape-(M, N) array of distances between M-unlabeled \n",
    "        and N-labeled images, and N labels, we predict a label for each \n",
    "        of the M images based on its k-nearest neighbors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dists : numpy.ndarray\n",
    "            `dists.shape` must be (M, N) where M is the number of\n",
    "            examples you wish to predict labels for, and N is \n",
    "            the number of labeled images used in the prediction\n",
    "        \n",
    "        labels : numpy.ndarray\n",
    "            A shape-(N,) array of class-IDs, of labels for the N images.    \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : numpy.array`\n",
    "            A shape-(M,) array of class-IDs, as predicted by the k-nearest\n",
    "            neighbors.\n",
    "    \"\"\"\n",
    "    #print(\"%%%\")\n",
    "    m = dists.shape[0]\n",
    "    n = dists.shape[1]\n",
    "    y_pred = np.zeros((m,), dtype=int)\n",
    "    for i in range(m):\n",
    "        knn = np.full(k, float('inf'))\n",
    "        knnIndex = np.full(k, -1)\n",
    "        alt = []\n",
    "        altIndex = []\n",
    "        Max = np.max(knn)\n",
    "        for j in range(n):\n",
    "            if dists[i][j]<Max:\n",
    "                maxIndex = np.argmax(knn)\n",
    "                knn[maxIndex] = dists[i][j]\n",
    "                knnIndex[maxIndex] = j\n",
    "                Max = np.max(knn)\n",
    "        for l in range(n):\n",
    "            if dists[i][l]==Max:\n",
    "                if l not in knnIndex:\n",
    "                    alt.append(dists[i][l])\n",
    "                    altIndex.append(l)\n",
    "        for p in range(len(alt)): #0, 1\n",
    "            maxInKnn = np.max(knn) #1\n",
    "            maxInKnnIndex = np.argmax(knn) #1\n",
    "            maxInLabels = labels[knnIndex[maxInKnnIndex]] #1\n",
    "            if labels[altIndex[p]] < maxInLabels: #0<1\n",
    "                knnIndex[maxInKnnIndex] = altIndex[p] #1=>4\n",
    "        maxcount = 0\n",
    "        eleMaxFreq = float('inf')\n",
    "        for ele1 in knnIndex: \n",
    "            count = 0\n",
    "            for ele2 in knnIndex: \n",
    "                if(labels[ele1] == labels[ele2]): \n",
    "                    #print(\"@@@\")\n",
    "                    count += 1\n",
    "            if count > maxcount or (count == maxcount and labels[ele1] < eleMaxFreq): \n",
    "                maxcount = count \n",
    "                eleMaxFreq = labels[ele1] \n",
    "        res = eleMaxFreq\n",
    "        y_pred[i] = res\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.nearest_neighbors import grade_predict\n",
    "grade_predict(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data points of shape (4, 2)\n",
    "toy_x_train = np.array([[0.7, -0.7],\n",
    "                       [-0.7, -0.7],\n",
    "                       [0, 0.7],\n",
    "                       [0, 0]\n",
    "                      ])\n",
    "# create class-labels of shape (4,)\n",
    "toy_y_train = np.array([0, 1, 2, 3])\n",
    "\n",
    "# define class colors \n",
    "toy_label_colors = {0: 'b',  # class 0 is blue\n",
    "                    1: 'y',  # class 1 is yellow \n",
    "                    2: 'g',  # class 2 is green\n",
    "                    3: 'r'}  # class 3 is is red\n",
    "\n",
    "# Create a set of densly sampled points in the range [-1, 1]\n",
    "xv, yv = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n",
    "toy_x_test = np.stack((xv, yv), axis=-1).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_data(x_train, y_train, x_test, test_predictions=np.empty(0)):\n",
    "    \"\"\" Plot data color coded by class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : numpy.ndarray\n",
    "        Training data of shape (N, 2).\n",
    "    \n",
    "    y_train : numpy.ndarray\n",
    "        Training labels of shape (N,).\n",
    "    \n",
    "    x_test : numpy.ndarray\n",
    "        Test data of shape (M, 2).\n",
    "    \n",
    "    test_predictions : numpy.ndarray, optional (default=np.array([]))\n",
    "        Test predictions. If no argument is given the points \n",
    "        `x_test` are given the default color code.\n",
    "    \"\"\"\n",
    "    # if no test predictions are given, use the default color\n",
    "    # otherwise, find the corresponding class color\n",
    "    if len(test_predictions) == 0:\n",
    "        test_pt_colors = 'C0'\n",
    "    else:\n",
    "        test_pt_colors = [toy_label_colors[l] for l in test_predictions]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(*x_test.T, c=test_pt_colors, alpha=0.1)\n",
    "    ax.scatter(*x_train.T, c=[toy_label_colors[l] for l in y_train])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_data(toy_x_train, toy_y_train, toy_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = compute_distances(toy_x_test, toy_x_train)\n",
    "predictions = predict(dists, toy_y_train)\n",
    "plot_2d_data(toy_x_train, toy_y_train, toy_x_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noisy_clusters(x, y, std=0.2, n_cluster_points=100):\n",
    "    \"\"\" Generate clusters around data points by adding random noise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray\n",
    "        Data points of shape (N, 2).\n",
    "        \n",
    "    y : numpy.ndarray\n",
    "        Labels of data points `x` of shape (N,).\n",
    "        \n",
    "    std : float\n",
    "        Standard deviation of noise used to generate clusters.\n",
    "        \n",
    "    n_cluster_points : int, optional (default=100)\n",
    "        Number of data points to generate around each point in `x`.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[numpy.ndarray, numpy.ndarray]\n",
    "        Arrays of shapes (`n_cluster_points`*N, 2) and (`n_cluster_points`*N,)\n",
    "        Containing the data clusters and their labels.\n",
    "    \"\"\"\n",
    "    toy_clusters_x = (np.repeat(x, n_cluster_points, axis=0) \\\n",
    "                      + std * np.random.randn(n_cluster_points*x.shape[0], 2)).clip(-1, 1)\n",
    "    toy_clusters_y = np.repeat(y, n_cluster_points, axis=0)\n",
    "    \n",
    "    return toy_clusters_x, toy_clusters_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_points = 100\n",
    "moise_std = 0.2  # standard deviation of perturbations \n",
    "toy_clusters_x, toy_clusters_y = generate_noisy_clusters(toy_x_train, toy_y_train, moise_std, \n",
    "                                                         n_cluster_points)\n",
    "plot_2d_data(toy_clusters_x, toy_clusters_y, toy_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = compute_distances(toy_x_test, toy_clusters_x)\n",
    "predictions = predict(dists, toy_clusters_y)\n",
    "plot_2d_data(toy_clusters_x, toy_clusters_y, toy_x_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train_set_idxs = range(11)\n",
    "x_train_mini = x_train[mini_train_set_idxs]\n",
    "y_train_mini = y_train[mini_train_set_idxs]\n",
    "\n",
    "mini_test_set_idx = [11]\n",
    "x_test_mini = x_train[mini_test_set_idx]\n",
    "y_test_mini = y_train[mini_test_set_idx]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_test_mini.reshape(32, 32,  3).astype(\"uint8\"))  # we flattened the images earlier \n",
    "ax.set_title(f'class: {classes[int(y_test_mini)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = compute_distances(x_train_mini, x_test_mini) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=len(dists), figsize=(8, 3))\n",
    "\n",
    "fig.suptitle(f'Class and L2 distance to test image')\n",
    "for label_ind, dist in enumerate(dists[:, 0]):\n",
    "    axes[label_ind].imshow(x_train_mini[label_ind].astype('uint8').reshape(32, 32, 3))\n",
    "    axes[label_ind].axis('off')\n",
    "    axes[label_ind].set_title(f'{classes[int(y_train_mini[label_ind])]}\\n{dist:1.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = compute_distances(toy_x_test, toy_clusters_x)\n",
    "predictions = predict(dists, toy_clusters_y, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_data(toy_clusters_x, toy_clusters_y, toy_x_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds(x, num_folds):\n",
    "    \"\"\" Divides the array `x` along axis-0 into a list of equal-sized \n",
    "    sub-arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.ndarray, shape=(N, ...)\n",
    "        An array of one or more dimensions, to be split along axis-0\n",
    "    \n",
    "    num_folds : int \n",
    "        The number of equal-sized folds to split `x` into. \n",
    "        Assume that: 0 < num_folds <= N.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[numpy.ndarray]\n",
    "        A list of the sub-divided arrays\"\"\"\n",
    "    size = x.shape[0]//num_folds\n",
    "    List = []\n",
    "    for i in range(num_folds):\n",
    "        List.append(x[i*size:(i+1)*size])\n",
    "    return List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bwsi_grader.cogworks.nearest_neighbors import grade_make_folds\n",
    "grade_make_folds(make_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 5 fold in cross-validation\n",
    "num_folds = 5\n",
    "x_train_folds = make_folds(x_train, num_folds=num_folds)\n",
    "y_train_folds = make_folds(y_train, num_folds=num_folds)\n",
    "\n",
    "# evaluate classifier's accuracy for the following values of k\n",
    "k_values = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracies: a dictionary that map the k-value to the resulting list of n classifier accuracies, one accuracy value for each validation fold.\n",
    "accuracies = {}\n",
    "\n",
    "for a in k_values:\n",
    "    accuracies[a] = []\n",
    "print(accuracies)\n",
    "for fold_i in range(num_folds):\n",
    "    print(\"for\", fold_i, \"in range num_folds\")\n",
    "    validation_data = x_train_folds[fold_i]\n",
    "    remaining_arrays = [arr for i, arr in enumerate(x_train_folds) if i != fold_i]\n",
    "    labeled_data = np.vstack(remaining_arrays)\n",
    "    validation_labels = y_train_folds[fold_i]\n",
    "    remaining_labels = [arr2 for j, arr2 in enumerate(y_train_folds) if j != fold_i]\n",
    "    labels = np.concatenate(remaining_labels)\n",
    "    \n",
    "    for j in k_values:\n",
    "        print(\"for\", j,\"in k_values\")\n",
    "        dists = compute_distances(validation_data, labeled_data)\n",
    "        pred = predict(dists, labels, k=j)\n",
    "        county = 0\n",
    "        for i in range(len(validation_labels)):\n",
    "            if pred[i]==validation_labels[i]:\n",
    "                county+=1\n",
    "        accuracy = county/(len(validation_labels))\n",
    "        accuracies[j].append(accuracy)\n",
    "        print(\"Completed for\", j ,\"in k_values\")\n",
    "print(accuracies)\n",
    "print(\"Completed for ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if recorded the appropriate number of fold-accuracies, for each k-value\n",
    "assert sorted(accuracies) == k_values\n",
    "print(accuracies)\n",
    "for list_of_acc in accuracies.values():\n",
    "    print(list_of_acc)\n",
    "    assert len(list_of_acc) == num_folds\n",
    "print(\"Completed the current cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the n accuracies, for each k-value, along with the average accuracy\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for k in k_values:\n",
    "    print(k,\"in k_values\")\n",
    "    ax.scatter([k] * len(accuracies[k]), accuracies[k], marker=\"x\")\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(accuracies.items())])\n",
    "ax.errorbar(k_values, accuracies_mean, yerr=accuracies_std, label=\"mean accuracy\")\n",
    "ax.set_title('Cross-validation on k')\n",
    "ax.set_xlabel('k')\n",
    "ax.set_ylabel('Cross-validation accuracy')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "print(\"Completed the current cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acc = list()\n",
    "for k in accuracies:\n",
    "    all_acc.extend(accuracies[k])\n",
    "print(max(all_acc))\n",
    "print(min(all_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "dists = compute_distances(x_test, x_train)\n",
    "labels = predict(dists, y_train, k)\n",
    "acc = np.mean(labels == y_test)\n",
    "round(float(acc), 3)\n",
    "print"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
